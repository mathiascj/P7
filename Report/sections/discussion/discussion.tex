\chapter{Discussion}\label{ch:discussion}
Having created our final implementation of our model and tabu search, we will discuss both in this chapter. These will be general thoughts on what we have produced, including what we could have done differently.

\input{sections/discussion/modeling}

\section{Tabu Search}
To pick a good configuration for producing an order of items we used the meta-heuristic known as tabu search. In this section we will discuss our generation of neighbours and use of memory in the implementation.

\subsection{Generating Neighbours}
In our implementation of the tabu search, we based our neighbour generation functions on the form transformation rules that we sat up earlier. However these functions are very different in how many neighbours we generate. Swap especially tends to generate a lot of different neighbours. Instead of generating all possible neighbours, it would instead be interesting to stochastically generate neighbourhoods. By just generating a subset of neighbours which are picked stochastically, we could equalize the  amount of neighbours that we evaluate at each iteration. Thus more of the total search time may be spend on interesting backtracking using long term memory, which may be more beneficial to the search.

Each of the three neighbourhood functions has a certain probability of being picked. We looked into having these probabilities altered as more search iterations are performed. Thus changing the search rules. Our basic implementation made it very likely to do anti-serializations first, but as time goes on, parallelization and swap become more likely. The idea being that anti-serialization sets up some basic configuration structure, which the others can then alter in less dramatic ways. It would be interesting to look more into, how we may change up our search rules, and when this should happen.

\subsection{Using Memory}
We discover that short term memory is not used that often during search. This is because our transformation rules has a very low chance of later generating the same configurationn. This may only occasionally happen when we generate neighbours using swap. Short term memory is sometimes used, when we backtrack using long term memory. Yet only if we backtrack to a recent element in long term memory, where it's earlier best neighbour is still in short term memory.

Long term could also be used in a more interesting way. Right now it has unlimited size and every frontier picked is stored within it. We also only use it to backtrack in the case that we find no better frontier. A possibility of backtracking using long term, which increases at each iteration, could allow us to backtrack more and search new areas. 

It could be interesting to define a memory not as a configuration, but as a set of attribute values. Thus we would be able to catch more unwanted neighbours using the short term memory. The issue here being how to meaningfully describe a configuration only by a few attributes, which can be used to guide search. 


